{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd8b42d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "\n",
    "from pylib.tlsh_lib import *\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "868abdbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of Function\n",
    "def getResult(hashType, clusterType, labelList, clusterNumber):\n",
    "    data = tlist2cdata(hashList)\n",
    "    \n",
    "    d = {word: key for key, word in enumerate(set(labelList))}\n",
    "    labelList_id = [d[word] for word in labelList]\n",
    "    \n",
    "    outlierRemoveLabel = []\n",
    "    outlierRemoveID = []\n",
    "    outlierRemoveData = []\n",
    "    \n",
    "    for i in range(len(clusterNumber)):\n",
    "        if clusterNumber[i] >= 0:\n",
    "            outlierRemoveLabel.append(clusterNumber[i])\n",
    "            outlierRemoveID.append(labelList_id[i])\n",
    "            outlierRemoveData.append(data[i])\n",
    "            \n",
    "    #print(\"labelList_id=\", labelList_id)\n",
    "    #print(\"cluster labels=\",clusterNumber)\n",
    "    #print(\"outlierRemoveLabel =\", outlierRemoveLabel)\n",
    "    #print(\"outlierRemoveData =\", outlierRemoveData)\n",
    "    \n",
    "    # Number of decimal place for score\n",
    "    dp = 4 \n",
    "    \n",
    "    homo = round(metrics.homogeneity_score(outlierRemoveID, outlierRemoveLabel), dp)\n",
    "    silh1 = round(metrics.silhouette_score(data, clusterNumber, metric=sim), dp)\n",
    "    silh2 = round(metrics.silhouette_score(outlierRemoveData, outlierRemoveLabel, metric=sim), dp)\n",
    "    #cali = round(metrics.calinski_harabasz_score(outlierRemoveData, outlierRemoveLabel), dp)\n",
    "    #dav = round(metrics.davies_bouldin_score(outlierRemoveData, outlierRemoveLabel), dp)\n",
    "    \n",
    "    print(clusterType + \" ran in \" + str(end) + \" seconds\")\n",
    "    print(\"Homogeneity score =\",homo)\n",
    "    print(\"Silhouette score =\",silh1)\n",
    "    print(\"Silhouette score with Outlier Remove =\",silh2)\n",
    "    #print(\"Calinski harabasz score =\",cali)\n",
    "    #print(\"Davies bouldin score =\",dav)\n",
    "    #print(metrics.silhouette_samples(outlierRemoveData, outlierRemoveLabel, metric=sim))\n",
    "    print()\n",
    "    \n",
    "    result = {\"nSample\": int(len(tlist)),\n",
    "              \"Hash\": str(hashType),\n",
    "              \"Cluster\": str(clusterType),\n",
    "              \"nLabel\": int(nlabel),\n",
    "              \"nCluster\": int(max(clusterNumber)),\n",
    "              \"Time(s)\": float(end),\n",
    "              \"Homogeneity\": float(homo),\n",
    "              \"Silhouette\": float(silh2)\n",
    "              #\"Cal.\": float(cali),\n",
    "              #\"Dav.\": float(dav)\n",
    "             }\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8614b4a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples is 99989\n",
      "Number of Unique Label is 379\n",
      "Example hash: T10263F782BC80EA22C7C01677FE6F518E331567D8E1EA32429D155FA07A8FC1B0D5B786\n"
     ]
    }
   ],
   "source": [
    "datafile = \"dataDir/mb_100000.csv\" #<-----Change this file size\n",
    "if (datafile == \"\"):\n",
    "    print(\"you must provide a datafile name (-f)\\n\")\n",
    "    sys.exit()\n",
    "\n",
    "tic = time.perf_counter()  # experiment time counter\n",
    "df = pd.DataFrame() #Result Table\n",
    "\n",
    "(path, file) = datafile.split(\"/\")  # save file path\n",
    "(filename, filetype) = file.split(\".\")  # save file type\n",
    "\n",
    "(tlist, [labelList, dateList, slist]) = tlsh_csvfile(datafile)  # return (tlshList, [labelList, dateList, ssdeepList])\n",
    "\n",
    "hashList = tlist\n",
    "\n",
    "print(\"Number of samples is \" + str(len(hashList)))\n",
    "print(\"Number of Unique Label is \" + str(len(set(labelList))))\n",
    "print(\"Example hash: \" + str(hashList[0]))\n",
    "nlabel = len(set(labelList))\n",
    "nClusters = [nlabel]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b5c5910e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agglomerative Clustering didn't work.\n",
      "Unable to allocate 74.5 GiB for an array with shape (99989, 99989) and data type float64\n"
     ]
    }
   ],
   "source": [
    "# Agglomerative Clustering\n",
    "try:\n",
    "    start = time.perf_counter()\n",
    "    res = assignCluster(hashList, nlabel)\n",
    "    end = round(time.perf_counter() - start, 4)\n",
    "\n",
    "    dict = getResult(\"tlsh\", \"ac\", labelList, res.labels_)\n",
    "    df = pd.concat((df, pd.DataFrame([dict])), ignore_index=True)\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"Agglomerative Clustering didn't work.\")\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d6d09953",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dbscan ran in 6120.2715 seconds\n",
      "Homogeneity score = 0.8992\n",
      "Silhouette score = 0.3147\n",
      "Silhouette score with Outlier Remove = 0.8095\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# DBSCAN\n",
    "from pylib.hac_lib import *\n",
    "try:\n",
    "    resetDistCalc()\n",
    "\n",
    "    start = time.perf_counter()\n",
    "    res = runDBSCAN(hashList, eps=30, min_samples=2, algorithm='auto')\n",
    "    end = round(time.perf_counter() - start, 4)\n",
    "\n",
    "    dict = getResult(\"tlsh\", \"dbscan\", labelList, res.labels_)\n",
    "    df = pd.concat((df, pd.DataFrame([dict])), ignore_index=True)\n",
    "\n",
    "    nclusters = max(res.labels_)\n",
    "    nDistCalc = lookupDistCalc()\n",
    "    #print(\"nclusters is \" + str(nclusters))\n",
    "    #print(\"nDistCalc is \" + str(nDistCalc))\n",
    "\n",
    "    nClusters.append(nclusters)\n",
    "\n",
    "    #outfile = path + \"/output/\" + filename + \"_dbscan_out.txt\"\n",
    "    #outputClusters(outfile, hashList, res.labels_, labelList, quiet=True)\n",
    "    \n",
    "except Exception as e:\n",
    "    print(\"DBSCAN didn't work.\")\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "67021186",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hac-t ran in 462.4878 seconds\n",
      "Homogeneity score = 0.9254\n",
      "Silhouette score = 0.3154\n",
      "Silhouette score with Outlier Remove = 0.8192\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# HAC-T\n",
    "from pylib.hac_lib import *\n",
    "try:\n",
    "    hac_resetDistCalc()\n",
    "\n",
    "    start = time.perf_counter()\n",
    "    res = HAC_T(datafile, CDist=30, step3=0, outfname=\"tmp.txt\", cenfname=\"tmp2.txt\")\n",
    "    end = round(time.perf_counter() - start, 4)\n",
    "\n",
    "    dict = getResult(\"tlsh\", \"hac-t\", labelList, res)\n",
    "    df = pd.concat((df, pd.DataFrame([dict])), ignore_index=True)\n",
    "\n",
    "    nclusters = max(res)\n",
    "    nDistCalc = hac_lookupDistCalc()\n",
    "    #print(\"nclusters is \" + str(nclusters))\n",
    "    #print(\"nDistCalc is \" + str(nDistCalc))\n",
    "\n",
    "    nClusters.append(nclusters)\n",
    "\n",
    "    #outfile = path + \"/output/\" + filename + \"_hac-t_out.txt\"\n",
    "    #outputClusters(outfile, hashList, res, labelList, quiet=True)\n",
    "    \n",
    "except Exception as e:\n",
    "    print(\"HAC-T didn't work.\")\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2e5545bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optics ran in 10623.5125 seconds\n",
      "Homogeneity score = 0.9394\n",
      "Silhouette score = 0.0838\n",
      "Silhouette score with Outlier Remove = 0.7109\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# OPTICS\n",
    "try:\n",
    "    start = time.perf_counter()\n",
    "    res = runOPTICS(hashList, min_samples=2)\n",
    "    end = round(time.perf_counter() - start, 4)\n",
    "\n",
    "    dict = getResult(\"tlsh\", \"optics\", labelList, res.labels_)\n",
    "    df = pd.concat((df, pd.DataFrame([dict])), ignore_index=True)\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"OPTICS didn't work.\")\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e7b370d5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# KMeans\\nfor i in nClusters:\\n    try:\\n        start = time.perf_counter()\\n        res = runKMean(hashList, n_clusters=i)\\n        end = round(time.perf_counter() - start, 4)\\n\\n        dict = getResult(\"tlsh\", \"kmeans\", labelList, res.labels_)\\n        df = pd.concat((df, pd.DataFrame([dict])), ignore_index=True)\\n        \\n    except Exception as e:\\n        print(\"KMeans didn\\'t work.\")\\n        print(e)\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "# KMeans\n",
    "for i in nClusters:\n",
    "    try:\n",
    "        start = time.perf_counter()\n",
    "        res = runKMean(hashList, n_clusters=i)\n",
    "        end = round(time.perf_counter() - start, 4)\n",
    "\n",
    "        dict = getResult(\"tlsh\", \"kmeans\", labelList, res.labels_)\n",
    "        df = pd.concat((df, pd.DataFrame([dict])), ignore_index=True)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(\"KMeans didn't work.\")\n",
    "        print(e)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0c12beb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# BIRCH\\nfor i in nClusters:\\n    try:\\n        start = time.perf_counter()\\n        res = runBIRCH(hashList, n_clusters=i)\\n        end = round(time.perf_counter() - start, 4)\\n\\n        dict = getResult(\"tlsh\", \"birch\", labelList, res.labels_)\\n        df = pd.concat((df, pd.DataFrame([dict])), ignore_index=True)\\n\\n    except Exception as e:\\n        print(\"BIRCH didn\\'t work.\")\\n        print(e)\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "# BIRCH\n",
    "for i in nClusters:\n",
    "    try:\n",
    "        start = time.perf_counter()\n",
    "        res = runBIRCH(hashList, n_clusters=i)\n",
    "        end = round(time.perf_counter() - start, 4)\n",
    "\n",
    "        dict = getResult(\"tlsh\", \"birch\", labelList, res.labels_)\n",
    "        df = pd.concat((df, pd.DataFrame([dict])), ignore_index=True)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"BIRCH didn't work.\")\n",
    "        print(e)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1f6c09c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# Affinity Propagation\\ntry:\\n    start = time.perf_counter()\\n    res = runAffinityPropagation(hashList, random_state=5)\\n    end = round(time.perf_counter() - start, 4)\\n\\n    dict = getResult(\"tlsh\", \"ap\", labelList, res.labels_)\\n    df = pd.concat((df, pd.DataFrame([dict])), ignore_index=True)\\n\\nexcept Exception as e:\\n    print(\"Affinity Propagation didn\\'t work.\")\\n    print(e)\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "# Affinity Propagation\n",
    "try:\n",
    "    start = time.perf_counter()\n",
    "    res = runAffinityPropagation(hashList, random_state=5)\n",
    "    end = round(time.perf_counter() - start, 4)\n",
    "\n",
    "    dict = getResult(\"tlsh\", \"ap\", labelList, res.labels_)\n",
    "    df = pd.concat((df, pd.DataFrame([dict])), ignore_index=True)\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"Affinity Propagation didn't work.\")\n",
    "    print(e)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bf509738",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# Mean Shift\\ntry:\\n    start = time.perf_counter()\\n    res = runMeanShift(hashList, bandwidth=5)\\n    end = round(time.perf_counter() - start, 4)\\n\\n    dict = getResult(\"tlsh\", \"ms\", labelList, res.labels_)\\n    df = pd.concat((df, pd.DataFrame([dict])), ignore_index=True)\\n\\nexcept Exception as e:\\n    print(\"Mean Shift didn\\'t work.\")\\n    print(e)\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "# Mean Shift\n",
    "try:\n",
    "    start = time.perf_counter()\n",
    "    res = runMeanShift(hashList, bandwidth=5)\n",
    "    end = round(time.perf_counter() - start, 4)\n",
    "\n",
    "    dict = getResult(\"tlsh\", \"ms\", labelList, res.labels_)\n",
    "    df = pd.concat((df, pd.DataFrame([dict])), ignore_index=True)\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"Mean Shift didn't work.\")\n",
    "    print(e)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0252f43e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# Spectral Clustering\\ntry:\\n    start = time.perf_counter()\\n    res = runSpectral(hashList, n_clusters=nlabel)\\n    end = round(time.perf_counter() - start, 4)\\n\\n    dict = getResult(\"tlsh\", \"sp\", labelList, res.labels_)\\n    df = pd.concat((df, pd.DataFrame([dict])), ignore_index=True)\\n\\nexcept Exception as e:\\n    print(\"Spectral Clustering didn\\'t work.\")\\n    print(e)\\n'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "# Spectral Clustering\n",
    "try:\n",
    "    start = time.perf_counter()\n",
    "    res = runSpectral(hashList, n_clusters=nlabel)\n",
    "    end = round(time.perf_counter() - start, 4)\n",
    "\n",
    "    dict = getResult(\"tlsh\", \"sp\", labelList, res.labels_)\n",
    "    df = pd.concat((df, pd.DataFrame([dict])), ignore_index=True)\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"Spectral Clustering didn't work.\")\n",
    "    print(e)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1f34b437",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All code ran in 50511.3651 seconds\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nSample</th>\n",
       "      <th>Hash</th>\n",
       "      <th>Cluster</th>\n",
       "      <th>nLabel</th>\n",
       "      <th>nCluster</th>\n",
       "      <th>Time(s)</th>\n",
       "      <th>Homogeneity</th>\n",
       "      <th>Silhouette</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>99989</td>\n",
       "      <td>tlsh</td>\n",
       "      <td>dbscan</td>\n",
       "      <td>379</td>\n",
       "      <td>4307</td>\n",
       "      <td>6120.2715</td>\n",
       "      <td>0.8992</td>\n",
       "      <td>0.8095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>99989</td>\n",
       "      <td>tlsh</td>\n",
       "      <td>hac-t</td>\n",
       "      <td>379</td>\n",
       "      <td>5321</td>\n",
       "      <td>462.4878</td>\n",
       "      <td>0.9254</td>\n",
       "      <td>0.8192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>99989</td>\n",
       "      <td>tlsh</td>\n",
       "      <td>optics</td>\n",
       "      <td>379</td>\n",
       "      <td>17371</td>\n",
       "      <td>10623.5125</td>\n",
       "      <td>0.9394</td>\n",
       "      <td>0.7109</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   nSample  Hash Cluster  nLabel  nCluster     Time(s)  Homogeneity  \\\n",
       "0    99989  tlsh  dbscan     379      4307   6120.2715       0.8992   \n",
       "1    99989  tlsh   hac-t     379      5321    462.4878       0.9254   \n",
       "2    99989  tlsh  optics     379     17371  10623.5125       0.9394   \n",
       "\n",
       "   Silhouette  \n",
       "0      0.8095  \n",
       "1      0.8192  \n",
       "2      0.7109  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Output\n",
    "outfile = path + \"/output/\" + filename + \"_Tlsh_result.csv\"\n",
    "df.to_csv(outfile, index=False)\n",
    "\n",
    "toc = round(time.perf_counter() - tic, 4)\n",
    "\n",
    "print(\"All code ran in \" + str(toc) + \" seconds\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c2bc51",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
