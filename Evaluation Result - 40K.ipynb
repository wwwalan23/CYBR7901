{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd8b42d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "\n",
    "from pylib.tlsh_lib import *\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "868abdbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of Function\n",
    "def getResult(hashType, clusterType, labelList, clusterNumber):\n",
    "    data = tlist2cdata(hashList)\n",
    "    \n",
    "    d = {word: key for key, word in enumerate(set(labelList))}\n",
    "    labelList_id = [d[word] for word in labelList]\n",
    "    \n",
    "    outlierRemoveLabel = []\n",
    "    outlierRemoveID = []\n",
    "    outlierRemoveData = []\n",
    "    \n",
    "    # Number of decimal place for score\n",
    "    dp = 4 \n",
    "    \n",
    "    for i in range(len(clusterNumber)):\n",
    "        if clusterNumber[i] >= 0:\n",
    "            outlierRemoveLabel.append(clusterNumber[i])\n",
    "            outlierRemoveID.append(labelList_id[i])\n",
    "            outlierRemoveData.append(data[i])\n",
    "            \n",
    "    #print(\"labelList_id=\", labelList_id)\n",
    "    #print(\"cluster labels=\",clusterNumber)\n",
    "    #print(\"outlierRemoveLabel =\", outlierRemoveLabel)\n",
    "    #print(\"outlierRemoveData =\", outlierRemoveData)\n",
    "    \n",
    "    homo = round(metrics.homogeneity_score(outlierRemoveID, outlierRemoveLabel), dp)\n",
    "    silh1 = round(metrics.silhouette_score(data, clusterNumber, metric=sim), dp)\n",
    "    silh2 = round(metrics.silhouette_score(outlierRemoveData, outlierRemoveLabel, metric=sim), dp)\n",
    "    #cali = round(metrics.calinski_harabasz_score(outlierRemoveData, outlierRemoveLabel), dp)\n",
    "    #dav = round(metrics.davies_bouldin_score(outlierRemoveData, outlierRemoveLabel), dp)\n",
    "    \n",
    "    coverage = len(outlierRemoveLabel)*100/len(clusterNumber)\n",
    "    coverage = round(coverage, dp)\n",
    "    \n",
    "    print(clusterType + \" ran in \" + str(end) + \" seconds\")\n",
    "    print(\"Homogeneity score =\",homo)\n",
    "    print(\"Silhouette score =\",silh1)\n",
    "    print(\"Silhouette score with Outlier Remove =\",silh2)\n",
    "    #print(\"Calinski harabasz score =\",cali)\n",
    "    #print(\"Davies bouldin score =\",dav)\n",
    "    #print(metrics.silhouette_samples(outlierRemoveData, outlierRemoveLabel, metric=sim))\n",
    "    print(\"% of coverage =\",coverage)\n",
    "    print()\n",
    "    \n",
    "    result = {\"nSample\": int(len(tlist)),\n",
    "              \"Hash\": str(hashType),\n",
    "              \"Cluster\": str(clusterType),\n",
    "              \"nLabel\": int(nlabel),\n",
    "              \"nCluster\": int(max(clusterNumber)),\n",
    "              \"Time(s)\": float(end),\n",
    "              \"Homogeneity\": float(homo),\n",
    "              \"Silhouette\": float(silh2),\n",
    "              #\"Cal.\": float(cali),\n",
    "              #\"Dav.\": float(dav),\n",
    "              \"Coverage(%)\": float(coverage)\n",
    "             }\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8614b4a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples is 1000\n",
      "Number of Unique Label is 63\n",
      "Example hash: T10263F782BC80EA22C7C01677FE6F518E331567D8E1EA32429D155FA07A8FC1B0D5B786\n"
     ]
    }
   ],
   "source": [
    "datafile = \"dataDir/mb_1000.csv\" #<-----Change this file size\n",
    "if (datafile == \"\"):\n",
    "    print(\"you must provide a datafile name (-f)\\n\")\n",
    "    sys.exit()\n",
    "\n",
    "tic = time.perf_counter()  # experiment time counter\n",
    "df = pd.DataFrame() #Result Table\n",
    "\n",
    "(path, file) = datafile.split(\"/\")  # save file path\n",
    "(filename, filetype) = file.split(\".\")  # save file type\n",
    "\n",
    "(tlist, [labelList, dateList, slist]) = tlsh_csvfile(datafile)  # return (tlshList, [labelList, dateList, ssdeepList])\n",
    "\n",
    "hashList = tlist\n",
    "\n",
    "print(\"Number of samples is \" + str(len(hashList)))\n",
    "print(\"Number of Unique Label is \" + str(len(set(labelList))))\n",
    "print(\"Example hash: \" + str(hashList[0]))\n",
    "nlabel = len(set(labelList))\n",
    "nClusters = [nlabel]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b5c5910e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ac ran in 2.0144 seconds\n",
      "Homogeneity score = 0.5708\n",
      "Silhouette score = 0.3126\n",
      "Silhouette score with Outlier Remove = 0.3126\n",
      "% of coverage = 100.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Agglomerative Clustering\n",
    "try:\n",
    "    start = time.perf_counter()\n",
    "    res = assignCluster(hashList, nlabel)\n",
    "    end = round(time.perf_counter() - start, 4)\n",
    "\n",
    "    dict = getResult(\"tlsh\", \"ac\", labelList, res.labels_)\n",
    "    df = pd.concat((df, pd.DataFrame([dict])), ignore_index=True)\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"Agglomerative Clustering didn't work.\")\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d6d09953",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dbscan ran in 4.101 seconds\n",
      "Homogeneity score = 0.7968\n",
      "Silhouette score = -0.0341\n",
      "Silhouette score with Outlier Remove = 0.731\n",
      "% of coverage = 40.9\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# DBSCAN\n",
    "from pylib.hac_lib import *\n",
    "try:\n",
    "    resetDistCalc()\n",
    "\n",
    "    start = time.perf_counter()\n",
    "    res = runDBSCAN(hashList, eps=30, min_samples=2, algorithm='auto')\n",
    "    end = round(time.perf_counter() - start, 4)\n",
    "\n",
    "    dict = getResult(\"tlsh\", \"dbscan\", labelList, res.labels_)\n",
    "    df = pd.concat((df, pd.DataFrame([dict])), ignore_index=True)\n",
    "\n",
    "    nclusters = max(res.labels_)\n",
    "    nDistCalc = lookupDistCalc()\n",
    "    #print(\"nclusters is \" + str(nclusters))\n",
    "    #print(\"nDistCalc is \" + str(nDistCalc))\n",
    "\n",
    "    nClusters.append(nclusters)\n",
    "\n",
    "    #outfile = path + \"/output/\" + filename + \"_dbscan_out.txt\"\n",
    "    #outputClusters(outfile, hashList, res.labels_, labelList, quiet=True)\n",
    "    \n",
    "except Exception as e:\n",
    "    print(\"DBSCAN didn't work.\")\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "67021186",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hac-t ran in 0.8246 seconds\n",
      "Homogeneity score = 0.8542\n",
      "Silhouette score = -0.1316\n",
      "Silhouette score with Outlier Remove = 0.5195\n",
      "% of coverage = 40.3\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# HAC-T\n",
    "from pylib.hac_lib import *\n",
    "try:\n",
    "    hac_resetDistCalc()\n",
    "\n",
    "    start = time.perf_counter()\n",
    "    res = HAC_T(datafile, CDist=30, step3=0, outfname=\"tmp.txt\", cenfname=\"tmp2.txt\")\n",
    "    end = round(time.perf_counter() - start, 4)\n",
    "\n",
    "    dict = getResult(\"tlsh\", \"hac-t\", labelList, res)\n",
    "    df = pd.concat((df, pd.DataFrame([dict])), ignore_index=True)\n",
    "\n",
    "    nclusters = max(res)\n",
    "    nDistCalc = hac_lookupDistCalc()\n",
    "    #print(\"nclusters is \" + str(nclusters))\n",
    "    #print(\"nDistCalc is \" + str(nDistCalc))\n",
    "\n",
    "    nClusters.append(nclusters)\n",
    "\n",
    "    #outfile = path + \"/output/\" + filename + \"_hac-t_out.txt\"\n",
    "    #outputClusters(outfile, hashList, res, labelList, quiet=True)\n",
    "    \n",
    "except Exception as e:\n",
    "    print(\"HAC-T didn't work.\")\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2e5545bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optics ran in 7.0606 seconds\n",
      "Homogeneity score = 0.8776\n",
      "Silhouette score = 0.0311\n",
      "Silhouette score with Outlier Remove = 0.4754\n",
      "% of coverage = 62.2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# OPTICS\n",
    "try:\n",
    "    start = time.perf_counter()\n",
    "    res = runOPTICS(hashList, min_samples=2)\n",
    "    end = round(time.perf_counter() - start, 4)\n",
    "\n",
    "    dict = getResult(\"tlsh\", \"optics\", labelList, res.labels_)\n",
    "    df = pd.concat((df, pd.DataFrame([dict])), ignore_index=True)\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"OPTICS didn't work.\")\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e7b370d5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# KMeans\\nfor i in nClusters:\\n    try:\\n        start = time.perf_counter()\\n        res = runKMean(hashList, n_clusters=i)\\n        end = round(time.perf_counter() - start, 4)\\n\\n        dict = getResult(\"tlsh\", \"kmeans\", labelList, res.labels_)\\n        df = pd.concat((df, pd.DataFrame([dict])), ignore_index=True)\\n        \\n    except Exception as e:\\n        print(\"KMeans didn\\'t work.\")\\n        print(e)\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "# KMeans\n",
    "for i in nClusters:\n",
    "    try:\n",
    "        start = time.perf_counter()\n",
    "        res = runKMean(hashList, n_clusters=i)\n",
    "        end = round(time.perf_counter() - start, 4)\n",
    "\n",
    "        dict = getResult(\"tlsh\", \"kmeans\", labelList, res.labels_)\n",
    "        df = pd.concat((df, pd.DataFrame([dict])), ignore_index=True)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(\"KMeans didn't work.\")\n",
    "        print(e)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0c12beb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# BIRCH\\nfor i in nClusters:\\n    try:\\n        start = time.perf_counter()\\n        res = runBIRCH(hashList, n_clusters=i)\\n        end = round(time.perf_counter() - start, 4)\\n\\n        dict = getResult(\"tlsh\", \"birch\", labelList, res.labels_)\\n        df = pd.concat((df, pd.DataFrame([dict])), ignore_index=True)\\n\\n    except Exception as e:\\n        print(\"BIRCH didn\\'t work.\")\\n        print(e)\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "# BIRCH\n",
    "for i in nClusters:\n",
    "    try:\n",
    "        start = time.perf_counter()\n",
    "        res = runBIRCH(hashList, n_clusters=i)\n",
    "        end = round(time.perf_counter() - start, 4)\n",
    "\n",
    "        dict = getResult(\"tlsh\", \"birch\", labelList, res.labels_)\n",
    "        df = pd.concat((df, pd.DataFrame([dict])), ignore_index=True)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"BIRCH didn't work.\")\n",
    "        print(e)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1f6c09c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# Affinity Propagation\\ntry:\\n    start = time.perf_counter()\\n    res = runAffinityPropagation(hashList, random_state=5)\\n    end = round(time.perf_counter() - start, 4)\\n\\n    dict = getResult(\"tlsh\", \"ap\", labelList, res.labels_)\\n    df = pd.concat((df, pd.DataFrame([dict])), ignore_index=True)\\n\\nexcept Exception as e:\\n    print(\"Affinity Propagation didn\\'t work.\")\\n    print(e)\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "# Affinity Propagation\n",
    "try:\n",
    "    start = time.perf_counter()\n",
    "    res = runAffinityPropagation(hashList, random_state=5)\n",
    "    end = round(time.perf_counter() - start, 4)\n",
    "\n",
    "    dict = getResult(\"tlsh\", \"ap\", labelList, res.labels_)\n",
    "    df = pd.concat((df, pd.DataFrame([dict])), ignore_index=True)\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"Affinity Propagation didn't work.\")\n",
    "    print(e)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bf509738",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# Mean Shift\\ntry:\\n    start = time.perf_counter()\\n    res = runMeanShift(hashList, bandwidth=5)\\n    end = round(time.perf_counter() - start, 4)\\n\\n    dict = getResult(\"tlsh\", \"ms\", labelList, res.labels_)\\n    df = pd.concat((df, pd.DataFrame([dict])), ignore_index=True)\\n\\nexcept Exception as e:\\n    print(\"Mean Shift didn\\'t work.\")\\n    print(e)\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "# Mean Shift\n",
    "try:\n",
    "    start = time.perf_counter()\n",
    "    res = runMeanShift(hashList, bandwidth=5)\n",
    "    end = round(time.perf_counter() - start, 4)\n",
    "\n",
    "    dict = getResult(\"tlsh\", \"ms\", labelList, res.labels_)\n",
    "    df = pd.concat((df, pd.DataFrame([dict])), ignore_index=True)\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"Mean Shift didn't work.\")\n",
    "    print(e)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0252f43e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# Spectral Clustering\\ntry:\\n    start = time.perf_counter()\\n    res = runSpectral(hashList, n_clusters=nlabel)\\n    end = round(time.perf_counter() - start, 4)\\n\\n    dict = getResult(\"tlsh\", \"sp\", labelList, res.labels_)\\n    df = pd.concat((df, pd.DataFrame([dict])), ignore_index=True)\\n\\nexcept Exception as e:\\n    print(\"Spectral Clustering didn\\'t work.\")\\n    print(e)\\n'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "# Spectral Clustering\n",
    "try:\n",
    "    start = time.perf_counter()\n",
    "    res = runSpectral(hashList, n_clusters=nlabel)\n",
    "    end = round(time.perf_counter() - start, 4)\n",
    "\n",
    "    dict = getResult(\"tlsh\", \"sp\", labelList, res.labels_)\n",
    "    df = pd.concat((df, pd.DataFrame([dict])), ignore_index=True)\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"Spectral Clustering didn't work.\")\n",
    "    print(e)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1f34b437",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All code ran in 25.8635 seconds\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nSample</th>\n",
       "      <th>Hash</th>\n",
       "      <th>Cluster</th>\n",
       "      <th>nLabel</th>\n",
       "      <th>nCluster</th>\n",
       "      <th>Time(s)</th>\n",
       "      <th>Homogeneity</th>\n",
       "      <th>Silhouette</th>\n",
       "      <th>Coverage(%)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000</td>\n",
       "      <td>tlsh</td>\n",
       "      <td>ac</td>\n",
       "      <td>63</td>\n",
       "      <td>62</td>\n",
       "      <td>2.0144</td>\n",
       "      <td>0.5708</td>\n",
       "      <td>0.3126</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000</td>\n",
       "      <td>tlsh</td>\n",
       "      <td>dbscan</td>\n",
       "      <td>63</td>\n",
       "      <td>57</td>\n",
       "      <td>4.1010</td>\n",
       "      <td>0.7968</td>\n",
       "      <td>0.7310</td>\n",
       "      <td>40.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000</td>\n",
       "      <td>tlsh</td>\n",
       "      <td>hac-t</td>\n",
       "      <td>63</td>\n",
       "      <td>75</td>\n",
       "      <td>0.8246</td>\n",
       "      <td>0.8542</td>\n",
       "      <td>0.5195</td>\n",
       "      <td>40.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000</td>\n",
       "      <td>tlsh</td>\n",
       "      <td>optics</td>\n",
       "      <td>63</td>\n",
       "      <td>197</td>\n",
       "      <td>7.0606</td>\n",
       "      <td>0.8776</td>\n",
       "      <td>0.4754</td>\n",
       "      <td>62.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   nSample  Hash Cluster  nLabel  nCluster  Time(s)  Homogeneity  Silhouette  \\\n",
       "0     1000  tlsh      ac      63        62   2.0144       0.5708      0.3126   \n",
       "1     1000  tlsh  dbscan      63        57   4.1010       0.7968      0.7310   \n",
       "2     1000  tlsh   hac-t      63        75   0.8246       0.8542      0.5195   \n",
       "3     1000  tlsh  optics      63       197   7.0606       0.8776      0.4754   \n",
       "\n",
       "   Coverage(%)  \n",
       "0        100.0  \n",
       "1         40.9  \n",
       "2         40.3  \n",
       "3         62.2  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Output\n",
    "outfile = path + \"/output/\" + filename + \"_Tlsh_result.csv\"\n",
    "df.to_csv(outfile, index=False)\n",
    "\n",
    "toc = round(time.perf_counter() - tic, 4)\n",
    "\n",
    "print(\"All code ran in \" + str(toc) + \" seconds\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c2bc51",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
