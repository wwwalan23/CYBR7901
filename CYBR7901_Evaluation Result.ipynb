{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b6c9fa24",
   "metadata": {},
   "source": [
    "# Evaluation Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a67543be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from pylib.tlsh_lib import *\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "tic = time.perf_counter() # experiment time counter "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a924d36b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove NaN function\n",
    "nan = False\n",
    "def containNan(labelList):\n",
    "    for lable in labelList:\n",
    "        if lable == 'n/a':\n",
    "            nan = True\n",
    "            return nan\n",
    "        \n",
    "def removeNan(hashlist, labelList):\n",
    "    count = -1\n",
    "    newhashlist = []\n",
    "    newlabelList = []\n",
    "    \n",
    "    for lable in labelList:\n",
    "        count += 1\n",
    "        if lable != 'n/a':\n",
    "            newhashlist.append(hashlist[count])\n",
    "            newlabelList.append(labelList[count])\n",
    "    return newhashlist, newlabelList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "89ccbaa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples is 1000\n",
      "Number of Unique Lable is 56\n",
      "['12288:TcinWHCM2K4C2fut2I2U9WLDQ9RnX/lmSG02h8W62NtYy:TR3CBtNTpWNT6y', '12288:3b1f+WVBULxM6IdO6r1uH38W9D+4ncY2BdcvwGqIg3/FTj32c4zWKO:rB+s8eOOI38z4cXSwKg3p7Vx', '12288:lH1rtcf9uFvwrp+8uGqARQi1+3lwbcSpsPP7r9r/+ppppppppppppppppppppppJ:VzF8oQXSi1Oevw1q', '12288:0jdRStsZZzk8/dRStsZZzkldRStsZZzkbgoPYj3YnSn93kEcnVAcx6lQr1Mjg9W2:NCdktCdkiCdkbkjInJmcIlQGjZCRClk', '12288:sULkUtcX1J7ygKXcNxa64qnYDNWXpcJyQPRI8rv:sUL9tcFJ7ygAcUWsyiRI87', '768:dLt2gJbT/5wQu2rNnFfIr8t7sJmn3P5DBlyF8yPyeJ8YH+Rs+FWYQw+6VzBTPv7r:L3JbTBwQuA5Fm86+dBlyFzyeJ8U+FWYj', '12288:dYWWHCM2K4CUY4lbFe5h5LtEjthcgbdQtAa+xaan:J3CUH9KLOTFtxa+', '12288:vjBID6xsmQECVwPvjY/P5vaDx9r4A7Pm6r0c8Ayfk4MwzqEj:a5nGahKx9lrVr0nAT10j', '12288:9ULkUtcX1J7ygKXcNxa64qnYDNWXpcJyQPRI8rA:9UL9tcFJ7ygAcUWsyiRI8s', '24576:G+oELLuVzvLM223WfM8oFJYEVOdsCDd3lF4iDWz3lbWaDTvT:hoEfkzDM2sL862tDd3AQWz1blPr']\n"
     ]
    }
   ],
   "source": [
    "datafile = \"dataDir2/mb_1K.csv\" #<----------Change this file size\n",
    "\n",
    "(path,file) = datafile.split(\"/\") #save file path\n",
    "(filename,filetype) = file.split(\".\") #save file type\n",
    "\n",
    "(tlist, [labelList, dateList, hashList]) = tlsh_csvfile(datafile) # return (tlist, [labelList, dateList, hashList])\n",
    "#(tlist, labelList) = tlsh_csvfile(datafile) \n",
    "\n",
    "#remove Nan Value\n",
    "#(tlist, labelList) = removeNan(tlist, labelList)\n",
    "\n",
    "print(\"Number of samples is \" + str(len(tlist)))\n",
    "print(\"Number of Unique Lable is \" + str(len(set(labelList))))\n",
    "print(hashList[0:10])\n",
    "nlable = len(set(labelList))\n",
    "nan = containNan(labelList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1f08e0d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "\n",
    "def getResult(fh,c,labelList, clusterNumber):\n",
    "    d = {word: key for key, word in enumerate(set(labelList))}\n",
    "    labelList_id = [d[word] for word in labelList]\n",
    "    a = np.array(labelList_id).reshape(-1, 1)\n",
    "    \n",
    "    #decimal place\n",
    "    dp = 4\n",
    "    \n",
    "    homo = round(metrics.homogeneity_score(labelList_id, clusterNumber),dp)\n",
    "    silh = round(metrics.silhouette_score(a, clusterNumber, metric='euclidean'),dp)\n",
    "    cali = round(metrics.calinski_harabasz_score(a, clusterNumber),dp)\n",
    "    dav = round(metrics.davies_bouldin_score(a, clusterNumber),dp)\n",
    "    \n",
    "    print(\"Homogeneity score is \" + str(homo))\n",
    "    print(\"Silhouette score is \" + str(silh))\n",
    "    print(\"Calinski harabasz score is \" + str(cali))\n",
    "    print(\"Davies bouldin score is \" + str(dav))\n",
    "    \n",
    "    result = {\"File\": str(filename),\n",
    "              \"nSample\": int(len(tlist)),\n",
    "              \"Hash\": str(fh),\n",
    "              \"Cluster\": str(c),\n",
    "              \"Has_n/a\": bool(nan),\n",
    "              \"nLabel\": int(nlable),\n",
    "              \"nCluster\": int(max(clusterNumber)),\n",
    "              \"Time(s)\": float(end),\n",
    "              \"Homo.\":float(homo),\n",
    "              \"Sil.\":float(silh),\n",
    "              \"Cal.\":float(cali),\n",
    "              \"Dav.\":float(dav)}\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd3f83a4",
   "metadata": {},
   "source": [
    "# TLSH Agglomerative Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a5a6a8ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Code ran in 0.5555 seconds\n",
      "Homogeneity score is 0.4868\n",
      "Silhouette score is -0.5577\n",
      "Calinski harabasz score is 5.7499\n",
      "Davies bouldin score is 143.9414\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File</th>\n",
       "      <th>nSample</th>\n",
       "      <th>Hash</th>\n",
       "      <th>Cluster</th>\n",
       "      <th>Has_n/a</th>\n",
       "      <th>nLabel</th>\n",
       "      <th>nCluster</th>\n",
       "      <th>Time(s)</th>\n",
       "      <th>Homo.</th>\n",
       "      <th>Sil.</th>\n",
       "      <th>Cal.</th>\n",
       "      <th>Dav.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mb_1K</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>tlsh</td>\n",
       "      <td>hac</td>\n",
       "      <td>1.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>0.5555</td>\n",
       "      <td>0.4868</td>\n",
       "      <td>-0.5577</td>\n",
       "      <td>5.7499</td>\n",
       "      <td>143.9414</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    File  nSample  Hash Cluster  Has_n/a  nLabel  nCluster  Time(s)   Homo.  \\\n",
       "0  mb_1K   1000.0  tlsh     hac      1.0    56.0      55.0   0.5555  0.4868   \n",
       "\n",
       "     Sil.    Cal.      Dav.  \n",
       "0 -0.5577  5.7499  143.9414  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start = time.perf_counter()\n",
    "\n",
    "clusterNumber = assignCluster(tlist, nlable)\n",
    "\n",
    "end = round(time.perf_counter() - start,4)\n",
    "print(\"Code ran in \" + str(end) + \" seconds\")\n",
    "\n",
    "#outfile = path + \"/output/\" + filename + \"_hac_out.txt\"\n",
    "#outputClusters(outfile, tlist, clusterNumber, labelList, quiet=True)\n",
    "\n",
    "dict = getResult(\"tlsh\",\"hac\",labelList,clusterNumber)\n",
    "df = df.append(dict, ignore_index = True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee8c737",
   "metadata": {},
   "source": [
    "# TLSH HAC-T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b2199235",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Code ran in 0.235 seconds\n",
      "Number of cluster is 85\n",
      "Number of Distance Calculated is 227245\n",
      "Homogeneity score is 0.3453\n",
      "Silhouette score is -0.7047\n",
      "Calinski harabasz score is 3.4985\n",
      "Davies bouldin score is 35.8058\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File</th>\n",
       "      <th>nSample</th>\n",
       "      <th>Hash</th>\n",
       "      <th>Cluster</th>\n",
       "      <th>Has_n/a</th>\n",
       "      <th>nLabel</th>\n",
       "      <th>nCluster</th>\n",
       "      <th>Time(s)</th>\n",
       "      <th>Homo.</th>\n",
       "      <th>Sil.</th>\n",
       "      <th>Cal.</th>\n",
       "      <th>Dav.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mb_1K</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>tlsh</td>\n",
       "      <td>hac</td>\n",
       "      <td>1.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>0.5555</td>\n",
       "      <td>0.4868</td>\n",
       "      <td>-0.5577</td>\n",
       "      <td>5.7499</td>\n",
       "      <td>143.9414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mb_1K</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>tlsh</td>\n",
       "      <td>hac-t</td>\n",
       "      <td>1.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>0.2350</td>\n",
       "      <td>0.3453</td>\n",
       "      <td>-0.7047</td>\n",
       "      <td>3.4985</td>\n",
       "      <td>35.8058</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    File  nSample  Hash Cluster  Has_n/a  nLabel  nCluster  Time(s)   Homo.  \\\n",
       "0  mb_1K   1000.0  tlsh     hac      1.0    56.0      55.0   0.5555  0.4868   \n",
       "1  mb_1K   1000.0  tlsh   hac-t      1.0    56.0      85.0   0.2350  0.3453   \n",
       "\n",
       "     Sil.    Cal.      Dav.  \n",
       "0 -0.5577  5.7499  143.9414  \n",
       "1 -0.7047  3.4985   35.8058  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pylib.hac_lib  import *\n",
    "\n",
    "hac_resetDistCalc()\n",
    "start = time.perf_counter()\n",
    "\n",
    "res = HAC_T(datafile, CDist=30, step3=0, outfname=\"tmp.txt\", cenfname=\"tmp2.txt\") \n",
    "\n",
    "end = round(time.perf_counter() - start,4)\n",
    "print(\"Code ran in \" + str(end) + \" seconds\")\n",
    "\n",
    "#outfile = path + \"/output/\" + filename + \"_hac-t_out.txt\"\n",
    "#outputClusters(outfile, tlist, res, labelList, quiet=True)\n",
    "\n",
    "nclusters = max(res)\n",
    "nDistCalc = hac_lookupDistCalc()\n",
    "\n",
    "print(\"Number of cluster is \" + str(nclusters))\n",
    "print(\"Number of Distance Calculated is \" + str(nDistCalc))\n",
    "\n",
    "dict = getResult(\"tlsh\",\"hac-t\",labelList,res)\n",
    "df = df.append(dict, ignore_index = True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbada2be",
   "metadata": {},
   "source": [
    "# TLSH DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "72f27854",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Code ran in 0.9082 seconds\n",
      "nclusters is 71\n",
      "nDistCalc is 961443\n",
      "Homogeneity score is 0.3336\n",
      "Silhouette score is -0.7083\n",
      "Calinski harabasz score is 4.1939\n",
      "Davies bouldin score is 24.7111\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File</th>\n",
       "      <th>nSample</th>\n",
       "      <th>Hash</th>\n",
       "      <th>Cluster</th>\n",
       "      <th>Has_n/a</th>\n",
       "      <th>nLabel</th>\n",
       "      <th>nCluster</th>\n",
       "      <th>Time(s)</th>\n",
       "      <th>Homo.</th>\n",
       "      <th>Sil.</th>\n",
       "      <th>Cal.</th>\n",
       "      <th>Dav.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mb_1K</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>tlsh</td>\n",
       "      <td>hac</td>\n",
       "      <td>1.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>0.5555</td>\n",
       "      <td>0.4868</td>\n",
       "      <td>-0.5577</td>\n",
       "      <td>5.7499</td>\n",
       "      <td>143.9414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mb_1K</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>tlsh</td>\n",
       "      <td>hac-t</td>\n",
       "      <td>1.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>0.2350</td>\n",
       "      <td>0.3453</td>\n",
       "      <td>-0.7047</td>\n",
       "      <td>3.4985</td>\n",
       "      <td>35.8058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mb_1K</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>tlsh</td>\n",
       "      <td>dbscan</td>\n",
       "      <td>1.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>0.9082</td>\n",
       "      <td>0.3336</td>\n",
       "      <td>-0.7083</td>\n",
       "      <td>4.1939</td>\n",
       "      <td>24.7111</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    File  nSample  Hash Cluster  Has_n/a  nLabel  nCluster  Time(s)   Homo.  \\\n",
       "0  mb_1K   1000.0  tlsh     hac      1.0    56.0      55.0   0.5555  0.4868   \n",
       "1  mb_1K   1000.0  tlsh   hac-t      1.0    56.0      85.0   0.2350  0.3453   \n",
       "2  mb_1K   1000.0  tlsh  dbscan      1.0    56.0      71.0   0.9082  0.3336   \n",
       "\n",
       "     Sil.    Cal.      Dav.  \n",
       "0 -0.5577  5.7499  143.9414  \n",
       "1 -0.7047  3.4985   35.8058  \n",
       "2 -0.7083  4.1939   24.7111  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resetDistCalc()\n",
    "start = time.perf_counter()\n",
    "\n",
    "res = runDBSCAN(tlist, eps=30, min_samples=2, algorithm='auto')\n",
    "\n",
    "end = round(time.perf_counter() - start,4)\n",
    "print(\"Code ran in \" + str(end) + \" seconds\")\n",
    "\n",
    "#outfile = path + \"/output/\" + filename + \"_dbscan_out.txt\"\n",
    "#outputClusters(outfile, tlist, res.labels_, labelList, quiet=True)\n",
    "\n",
    "nclusters = max(res.labels_)\n",
    "nDistCalc = lookupDistCalc()\n",
    "\n",
    "print(\"nclusters is \" + str(nclusters))\n",
    "print(\"nDistCalc is \" + str(nDistCalc))\n",
    "\n",
    "dict = getResult(\"tlsh\",\"dbscan\",labelList,res.labels_)\n",
    "df = df.append(dict, ignore_index = True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb3645a4",
   "metadata": {},
   "source": [
    "# TLSH KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "66fafc57",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "def runKMean(tlist, n):\n",
    "    tdata = tlist2cdata(tlist)\n",
    "    res = KMeans(n_clusters=n, random_state=0).fit(tdata)\n",
    "    return(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e7fa3889",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Code ran in 0.1688 seconds\n",
      "Homogeneity score is 0.4641\n",
      "Silhouette score is -0.6218\n",
      "Calinski harabasz score is 3.9487\n",
      "Davies bouldin score is 342.2735\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File</th>\n",
       "      <th>nSample</th>\n",
       "      <th>Hash</th>\n",
       "      <th>Cluster</th>\n",
       "      <th>Has_n/a</th>\n",
       "      <th>nLabel</th>\n",
       "      <th>nCluster</th>\n",
       "      <th>Time(s)</th>\n",
       "      <th>Homo.</th>\n",
       "      <th>Sil.</th>\n",
       "      <th>Cal.</th>\n",
       "      <th>Dav.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mb_1K</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>tlsh</td>\n",
       "      <td>hac</td>\n",
       "      <td>1.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>0.5555</td>\n",
       "      <td>0.4868</td>\n",
       "      <td>-0.5577</td>\n",
       "      <td>5.7499</td>\n",
       "      <td>143.9414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mb_1K</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>tlsh</td>\n",
       "      <td>hac-t</td>\n",
       "      <td>1.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>0.2350</td>\n",
       "      <td>0.3453</td>\n",
       "      <td>-0.7047</td>\n",
       "      <td>3.4985</td>\n",
       "      <td>35.8058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mb_1K</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>tlsh</td>\n",
       "      <td>dbscan</td>\n",
       "      <td>1.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>0.9082</td>\n",
       "      <td>0.3336</td>\n",
       "      <td>-0.7083</td>\n",
       "      <td>4.1939</td>\n",
       "      <td>24.7111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mb_1K</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>tlsh</td>\n",
       "      <td>kmeans</td>\n",
       "      <td>1.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>0.1688</td>\n",
       "      <td>0.4641</td>\n",
       "      <td>-0.6218</td>\n",
       "      <td>3.9487</td>\n",
       "      <td>342.2735</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    File  nSample  Hash Cluster  Has_n/a  nLabel  nCluster  Time(s)   Homo.  \\\n",
       "0  mb_1K   1000.0  tlsh     hac      1.0    56.0      55.0   0.5555  0.4868   \n",
       "1  mb_1K   1000.0  tlsh   hac-t      1.0    56.0      85.0   0.2350  0.3453   \n",
       "2  mb_1K   1000.0  tlsh  dbscan      1.0    56.0      71.0   0.9082  0.3336   \n",
       "3  mb_1K   1000.0  tlsh  kmeans      1.0    56.0      55.0   0.1688  0.4641   \n",
       "\n",
       "     Sil.    Cal.      Dav.  \n",
       "0 -0.5577  5.7499  143.9414  \n",
       "1 -0.7047  3.4985   35.8058  \n",
       "2 -0.7083  4.1939   24.7111  \n",
       "3 -0.6218  3.9487  342.2735  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start = time.perf_counter()\n",
    "\n",
    "res = runKMean(tlist, nlable)\n",
    "\n",
    "end = round(time.perf_counter() - start,4)\n",
    "print(\"Code ran in \" + str(end) + \" seconds\")\n",
    "\n",
    "#outfile = path + \"/output/\" + filename + \"_kmean_out.txt\"\n",
    "#outputClusters(outfile, tlist, res.labels_, labelList)\n",
    "\n",
    "dict = getResult(\"tlsh\",\"kmeans\",labelList,res.labels_)\n",
    "df = df.append(dict, ignore_index = True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "47f1111c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28,\n",
       "        4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,\n",
       "        4,  4, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40,\n",
       "       40, 40, 40, 40, 40, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
       "       20, 20, 20, 20, 20, 20, 20, 20, 20, 34, 34, 34, 34, 34, 34, 34, 34,\n",
       "       34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34,  7,  7,  7,  7,  7,  7,\n",
       "        7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7, 48, 48, 48, 48, 48, 48,\n",
       "       48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 25, 25, 25, 25, 25, 25, 25,\n",
       "       25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 38, 38, 38, 38, 38, 38, 38,\n",
       "       38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 14, 14, 14, 14, 14, 14, 14,\n",
       "       14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 29, 29, 29, 29, 29, 29,\n",
       "       29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29,  1,  1,  1,\n",
       "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1, 46,\n",
       "       46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 30,\n",
       "       30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 45, 45, 45,\n",
       "       45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 12, 12, 12, 12,\n",
       "       12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 35, 35, 35,\n",
       "       35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 16, 16,\n",
       "       16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 27, 27, 27,\n",
       "       27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 52, 52, 52,\n",
       "       52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52,  6,  6,\n",
       "        6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,\n",
       "        6, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22,\n",
       "       22, 22, 22, 22, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41,\n",
       "       41, 41, 41, 41, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "       10, 10, 10, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53,\n",
       "       24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 51,\n",
       "       51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51,\n",
       "        2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,\n",
       "        2,  2,  2, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36,\n",
       "       36, 36, 36, 36, 36, 36, 36, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18,\n",
       "       18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 11, 11, 11, 11, 11, 11,\n",
       "       11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 55, 55, 55,\n",
       "       55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 19, 19, 19,\n",
       "       19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 39, 39, 39,\n",
       "       39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39,  5,  5,\n",
       "        5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,\n",
       "        5, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42,\n",
       "       42, 42, 42, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21,\n",
       "       21, 21, 21, 21, 21, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43,\n",
       "       43, 43, 43, 43, 43, 43,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,\n",
       "        8,  8,  8,  8,  8, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32,\n",
       "       32, 32, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49,\n",
       "       17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 33,\n",
       "       33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0, 50,\n",
       "       50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 23, 23,\n",
       "       23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 54, 54,\n",
       "       54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54,  9,  9,  9,\n",
       "        9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9, 47, 47, 47, 47, 47, 47,\n",
       "       47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 31, 31, 31, 31, 31, 31, 31,\n",
       "       31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 15, 15, 15, 15, 15, 15,\n",
       "       15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 37, 37, 37,\n",
       "       37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,  3,\n",
       "        3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,\n",
       "        3, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44,\n",
       "       44, 44, 44, 44, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13,\n",
       "       13, 13, 13, 13, 13, 13, 13, 13, 26, 26, 26, 26, 26, 26, 26, 26, 26,\n",
       "       26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.labels_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acdd6a3a",
   "metadata": {},
   "source": [
    "### Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7e2a64cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "outfile = path + \"/output/\" + filename + \"_result.csv\"\n",
    "df.to_csv(outfile, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f5e543c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.2239"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toc = round(time.perf_counter() - tic,4)\n",
    "toc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7439c64d",
   "metadata": {},
   "source": [
    "# Affinity Propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "15fa8718",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import AffinityPropagation\n",
    "\n",
    "def runAP(tlist,n):\n",
    "    tdata = tlist2cdata(tlist)\n",
    "    #print(tlist)\n",
    "    print(tdata)\n",
    "    res = AffinityPropagation(random_state=5).fit(tdata)\n",
    "    return(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e916d6b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0]\n",
      " [  1]\n",
      " [  2]\n",
      " [  3]\n",
      " [  4]\n",
      " [  5]\n",
      " [  6]\n",
      " [  7]\n",
      " [  8]\n",
      " [  9]\n",
      " [ 10]\n",
      " [ 11]\n",
      " [ 12]\n",
      " [ 13]\n",
      " [ 14]\n",
      " [ 15]\n",
      " [ 16]\n",
      " [ 17]\n",
      " [ 18]\n",
      " [ 19]\n",
      " [ 20]\n",
      " [ 21]\n",
      " [ 22]\n",
      " [ 23]\n",
      " [ 24]\n",
      " [ 25]\n",
      " [ 26]\n",
      " [ 27]\n",
      " [ 28]\n",
      " [ 29]\n",
      " [ 30]\n",
      " [ 31]\n",
      " [ 32]\n",
      " [ 33]\n",
      " [ 34]\n",
      " [ 35]\n",
      " [ 36]\n",
      " [ 37]\n",
      " [ 38]\n",
      " [ 39]\n",
      " [ 40]\n",
      " [ 41]\n",
      " [ 42]\n",
      " [ 43]\n",
      " [ 44]\n",
      " [ 45]\n",
      " [ 46]\n",
      " [ 47]\n",
      " [ 48]\n",
      " [ 49]\n",
      " [ 50]\n",
      " [ 51]\n",
      " [ 52]\n",
      " [ 53]\n",
      " [ 54]\n",
      " [ 55]\n",
      " [ 56]\n",
      " [ 57]\n",
      " [ 58]\n",
      " [ 59]\n",
      " [ 60]\n",
      " [ 61]\n",
      " [ 62]\n",
      " [ 63]\n",
      " [ 64]\n",
      " [ 65]\n",
      " [ 66]\n",
      " [ 67]\n",
      " [ 68]\n",
      " [ 69]\n",
      " [ 70]\n",
      " [ 71]\n",
      " [ 72]\n",
      " [ 73]\n",
      " [ 74]\n",
      " [ 75]\n",
      " [ 76]\n",
      " [ 77]\n",
      " [ 78]\n",
      " [ 79]\n",
      " [ 80]\n",
      " [ 81]\n",
      " [ 82]\n",
      " [ 83]\n",
      " [ 84]\n",
      " [ 85]\n",
      " [ 86]\n",
      " [ 87]\n",
      " [ 88]\n",
      " [ 89]\n",
      " [ 90]\n",
      " [ 91]\n",
      " [ 92]\n",
      " [ 93]\n",
      " [ 94]\n",
      " [ 95]\n",
      " [ 96]\n",
      " [ 97]\n",
      " [ 98]\n",
      " [ 99]\n",
      " [100]\n",
      " [101]\n",
      " [102]\n",
      " [103]\n",
      " [104]\n",
      " [105]\n",
      " [106]\n",
      " [107]\n",
      " [108]\n",
      " [109]\n",
      " [110]\n",
      " [111]\n",
      " [112]\n",
      " [113]\n",
      " [114]\n",
      " [115]\n",
      " [116]\n",
      " [117]\n",
      " [118]\n",
      " [119]\n",
      " [120]\n",
      " [121]\n",
      " [122]\n",
      " [123]\n",
      " [124]\n",
      " [125]\n",
      " [126]\n",
      " [127]\n",
      " [128]\n",
      " [129]\n",
      " [130]\n",
      " [131]\n",
      " [132]\n",
      " [133]\n",
      " [134]\n",
      " [135]\n",
      " [136]\n",
      " [137]\n",
      " [138]\n",
      " [139]\n",
      " [140]\n",
      " [141]\n",
      " [142]\n",
      " [143]\n",
      " [144]\n",
      " [145]\n",
      " [146]\n",
      " [147]\n",
      " [148]\n",
      " [149]\n",
      " [150]\n",
      " [151]\n",
      " [152]\n",
      " [153]\n",
      " [154]\n",
      " [155]\n",
      " [156]\n",
      " [157]\n",
      " [158]\n",
      " [159]\n",
      " [160]\n",
      " [161]\n",
      " [162]\n",
      " [163]\n",
      " [164]\n",
      " [165]\n",
      " [166]\n",
      " [167]\n",
      " [168]\n",
      " [169]\n",
      " [170]\n",
      " [171]\n",
      " [172]\n",
      " [173]\n",
      " [174]\n",
      " [175]\n",
      " [176]\n",
      " [177]\n",
      " [178]\n",
      " [179]\n",
      " [180]\n",
      " [181]\n",
      " [182]\n",
      " [183]\n",
      " [184]\n",
      " [185]\n",
      " [186]\n",
      " [187]\n",
      " [188]\n",
      " [189]\n",
      " [190]\n",
      " [191]\n",
      " [192]\n",
      " [193]\n",
      " [194]\n",
      " [195]\n",
      " [196]\n",
      " [197]\n",
      " [198]\n",
      " [199]\n",
      " [200]\n",
      " [201]\n",
      " [202]\n",
      " [203]\n",
      " [204]\n",
      " [205]\n",
      " [206]\n",
      " [207]\n",
      " [208]\n",
      " [209]\n",
      " [210]\n",
      " [211]\n",
      " [212]\n",
      " [213]\n",
      " [214]\n",
      " [215]\n",
      " [216]\n",
      " [217]\n",
      " [218]\n",
      " [219]\n",
      " [220]\n",
      " [221]\n",
      " [222]\n",
      " [223]\n",
      " [224]\n",
      " [225]\n",
      " [226]\n",
      " [227]\n",
      " [228]\n",
      " [229]\n",
      " [230]\n",
      " [231]\n",
      " [232]\n",
      " [233]\n",
      " [234]\n",
      " [235]\n",
      " [236]\n",
      " [237]\n",
      " [238]\n",
      " [239]\n",
      " [240]\n",
      " [241]\n",
      " [242]\n",
      " [243]\n",
      " [244]\n",
      " [245]\n",
      " [246]\n",
      " [247]\n",
      " [248]\n",
      " [249]\n",
      " [250]\n",
      " [251]\n",
      " [252]\n",
      " [253]\n",
      " [254]\n",
      " [255]\n",
      " [256]\n",
      " [257]\n",
      " [258]\n",
      " [259]\n",
      " [260]\n",
      " [261]\n",
      " [262]\n",
      " [263]\n",
      " [264]\n",
      " [265]\n",
      " [266]\n",
      " [267]\n",
      " [268]\n",
      " [269]\n",
      " [270]\n",
      " [271]\n",
      " [272]\n",
      " [273]\n",
      " [274]\n",
      " [275]\n",
      " [276]\n",
      " [277]\n",
      " [278]\n",
      " [279]\n",
      " [280]\n",
      " [281]\n",
      " [282]\n",
      " [283]\n",
      " [284]\n",
      " [285]\n",
      " [286]\n",
      " [287]\n",
      " [288]\n",
      " [289]\n",
      " [290]\n",
      " [291]\n",
      " [292]\n",
      " [293]\n",
      " [294]\n",
      " [295]\n",
      " [296]\n",
      " [297]\n",
      " [298]\n",
      " [299]\n",
      " [300]\n",
      " [301]\n",
      " [302]\n",
      " [303]\n",
      " [304]\n",
      " [305]\n",
      " [306]\n",
      " [307]\n",
      " [308]\n",
      " [309]\n",
      " [310]\n",
      " [311]\n",
      " [312]\n",
      " [313]\n",
      " [314]\n",
      " [315]\n",
      " [316]\n",
      " [317]\n",
      " [318]\n",
      " [319]\n",
      " [320]\n",
      " [321]\n",
      " [322]\n",
      " [323]\n",
      " [324]\n",
      " [325]\n",
      " [326]\n",
      " [327]\n",
      " [328]\n",
      " [329]\n",
      " [330]\n",
      " [331]\n",
      " [332]\n",
      " [333]\n",
      " [334]\n",
      " [335]\n",
      " [336]\n",
      " [337]\n",
      " [338]\n",
      " [339]\n",
      " [340]\n",
      " [341]\n",
      " [342]\n",
      " [343]\n",
      " [344]\n",
      " [345]\n",
      " [346]\n",
      " [347]\n",
      " [348]\n",
      " [349]\n",
      " [350]\n",
      " [351]\n",
      " [352]\n",
      " [353]\n",
      " [354]\n",
      " [355]\n",
      " [356]\n",
      " [357]\n",
      " [358]\n",
      " [359]\n",
      " [360]\n",
      " [361]\n",
      " [362]\n",
      " [363]\n",
      " [364]\n",
      " [365]\n",
      " [366]\n",
      " [367]\n",
      " [368]\n",
      " [369]\n",
      " [370]\n",
      " [371]\n",
      " [372]\n",
      " [373]\n",
      " [374]\n",
      " [375]\n",
      " [376]\n",
      " [377]\n",
      " [378]\n",
      " [379]\n",
      " [380]\n",
      " [381]\n",
      " [382]\n",
      " [383]\n",
      " [384]\n",
      " [385]\n",
      " [386]\n",
      " [387]\n",
      " [388]\n",
      " [389]\n",
      " [390]\n",
      " [391]\n",
      " [392]\n",
      " [393]\n",
      " [394]\n",
      " [395]\n",
      " [396]\n",
      " [397]\n",
      " [398]\n",
      " [399]\n",
      " [400]\n",
      " [401]\n",
      " [402]\n",
      " [403]\n",
      " [404]\n",
      " [405]\n",
      " [406]\n",
      " [407]\n",
      " [408]\n",
      " [409]\n",
      " [410]\n",
      " [411]\n",
      " [412]\n",
      " [413]\n",
      " [414]\n",
      " [415]\n",
      " [416]\n",
      " [417]\n",
      " [418]\n",
      " [419]\n",
      " [420]\n",
      " [421]\n",
      " [422]\n",
      " [423]\n",
      " [424]\n",
      " [425]\n",
      " [426]\n",
      " [427]\n",
      " [428]\n",
      " [429]\n",
      " [430]\n",
      " [431]\n",
      " [432]\n",
      " [433]\n",
      " [434]\n",
      " [435]\n",
      " [436]\n",
      " [437]\n",
      " [438]\n",
      " [439]\n",
      " [440]\n",
      " [441]\n",
      " [442]\n",
      " [443]\n",
      " [444]\n",
      " [445]\n",
      " [446]\n",
      " [447]\n",
      " [448]\n",
      " [449]\n",
      " [450]\n",
      " [451]\n",
      " [452]\n",
      " [453]\n",
      " [454]\n",
      " [455]\n",
      " [456]\n",
      " [457]\n",
      " [458]\n",
      " [459]\n",
      " [460]\n",
      " [461]\n",
      " [462]\n",
      " [463]\n",
      " [464]\n",
      " [465]\n",
      " [466]\n",
      " [467]\n",
      " [468]\n",
      " [469]\n",
      " [470]\n",
      " [471]\n",
      " [472]\n",
      " [473]\n",
      " [474]\n",
      " [475]\n",
      " [476]\n",
      " [477]\n",
      " [478]\n",
      " [479]\n",
      " [480]\n",
      " [481]\n",
      " [482]\n",
      " [483]\n",
      " [484]\n",
      " [485]\n",
      " [486]\n",
      " [487]\n",
      " [488]\n",
      " [489]\n",
      " [490]\n",
      " [491]\n",
      " [492]\n",
      " [493]\n",
      " [494]\n",
      " [495]\n",
      " [496]\n",
      " [497]\n",
      " [498]\n",
      " [499]\n",
      " [500]\n",
      " [501]\n",
      " [502]\n",
      " [503]\n",
      " [504]\n",
      " [505]\n",
      " [506]\n",
      " [507]\n",
      " [508]\n",
      " [509]\n",
      " [510]\n",
      " [511]\n",
      " [512]\n",
      " [513]\n",
      " [514]\n",
      " [515]\n",
      " [516]\n",
      " [517]\n",
      " [518]\n",
      " [519]\n",
      " [520]\n",
      " [521]\n",
      " [522]\n",
      " [523]\n",
      " [524]\n",
      " [525]\n",
      " [526]\n",
      " [527]\n",
      " [528]\n",
      " [529]\n",
      " [530]\n",
      " [531]\n",
      " [532]\n",
      " [533]\n",
      " [534]\n",
      " [535]\n",
      " [536]\n",
      " [537]\n",
      " [538]\n",
      " [539]\n",
      " [540]\n",
      " [541]\n",
      " [542]\n",
      " [543]\n",
      " [544]\n",
      " [545]\n",
      " [546]\n",
      " [547]\n",
      " [548]\n",
      " [549]\n",
      " [550]\n",
      " [551]\n",
      " [552]\n",
      " [553]\n",
      " [554]\n",
      " [555]\n",
      " [556]\n",
      " [557]\n",
      " [558]\n",
      " [559]\n",
      " [560]\n",
      " [561]\n",
      " [562]\n",
      " [563]\n",
      " [564]\n",
      " [565]\n",
      " [566]\n",
      " [567]\n",
      " [568]\n",
      " [569]\n",
      " [570]\n",
      " [571]\n",
      " [572]\n",
      " [573]\n",
      " [574]\n",
      " [575]\n",
      " [576]\n",
      " [577]\n",
      " [578]\n",
      " [579]\n",
      " [580]\n",
      " [581]\n",
      " [582]\n",
      " [583]\n",
      " [584]\n",
      " [585]\n",
      " [586]\n",
      " [587]\n",
      " [588]\n",
      " [589]\n",
      " [590]\n",
      " [591]\n",
      " [592]\n",
      " [593]\n",
      " [594]\n",
      " [595]\n",
      " [596]\n",
      " [597]\n",
      " [598]\n",
      " [599]\n",
      " [600]\n",
      " [601]\n",
      " [602]\n",
      " [603]\n",
      " [604]\n",
      " [605]\n",
      " [606]\n",
      " [607]\n",
      " [608]\n",
      " [609]\n",
      " [610]\n",
      " [611]\n",
      " [612]\n",
      " [613]\n",
      " [614]\n",
      " [615]\n",
      " [616]\n",
      " [617]\n",
      " [618]\n",
      " [619]\n",
      " [620]\n",
      " [621]\n",
      " [622]\n",
      " [623]\n",
      " [624]\n",
      " [625]\n",
      " [626]\n",
      " [627]\n",
      " [628]\n",
      " [629]\n",
      " [630]\n",
      " [631]\n",
      " [632]\n",
      " [633]\n",
      " [634]\n",
      " [635]\n",
      " [636]\n",
      " [637]\n",
      " [638]\n",
      " [639]\n",
      " [640]\n",
      " [641]\n",
      " [642]\n",
      " [643]\n",
      " [644]\n",
      " [645]\n",
      " [646]\n",
      " [647]\n",
      " [648]\n",
      " [649]\n",
      " [650]\n",
      " [651]\n",
      " [652]\n",
      " [653]\n",
      " [654]\n",
      " [655]\n",
      " [656]\n",
      " [657]\n",
      " [658]\n",
      " [659]\n",
      " [660]\n",
      " [661]\n",
      " [662]\n",
      " [663]\n",
      " [664]\n",
      " [665]\n",
      " [666]\n",
      " [667]\n",
      " [668]\n",
      " [669]\n",
      " [670]\n",
      " [671]\n",
      " [672]\n",
      " [673]\n",
      " [674]\n",
      " [675]\n",
      " [676]\n",
      " [677]\n",
      " [678]\n",
      " [679]\n",
      " [680]\n",
      " [681]\n",
      " [682]\n",
      " [683]\n",
      " [684]\n",
      " [685]\n",
      " [686]\n",
      " [687]\n",
      " [688]\n",
      " [689]\n",
      " [690]\n",
      " [691]\n",
      " [692]\n",
      " [693]\n",
      " [694]\n",
      " [695]\n",
      " [696]\n",
      " [697]\n",
      " [698]\n",
      " [699]\n",
      " [700]\n",
      " [701]\n",
      " [702]\n",
      " [703]\n",
      " [704]\n",
      " [705]\n",
      " [706]\n",
      " [707]\n",
      " [708]\n",
      " [709]\n",
      " [710]\n",
      " [711]\n",
      " [712]\n",
      " [713]\n",
      " [714]\n",
      " [715]\n",
      " [716]\n",
      " [717]\n",
      " [718]\n",
      " [719]\n",
      " [720]\n",
      " [721]\n",
      " [722]\n",
      " [723]\n",
      " [724]\n",
      " [725]\n",
      " [726]\n",
      " [727]\n",
      " [728]\n",
      " [729]\n",
      " [730]\n",
      " [731]\n",
      " [732]\n",
      " [733]\n",
      " [734]\n",
      " [735]\n",
      " [736]\n",
      " [737]\n",
      " [738]\n",
      " [739]\n",
      " [740]\n",
      " [741]\n",
      " [742]\n",
      " [743]\n",
      " [744]\n",
      " [745]\n",
      " [746]\n",
      " [747]\n",
      " [748]\n",
      " [749]\n",
      " [750]\n",
      " [751]\n",
      " [752]\n",
      " [753]\n",
      " [754]\n",
      " [755]\n",
      " [756]\n",
      " [757]\n",
      " [758]\n",
      " [759]\n",
      " [760]\n",
      " [761]\n",
      " [762]\n",
      " [763]\n",
      " [764]\n",
      " [765]\n",
      " [766]\n",
      " [767]\n",
      " [768]\n",
      " [769]\n",
      " [770]\n",
      " [771]\n",
      " [772]\n",
      " [773]\n",
      " [774]\n",
      " [775]\n",
      " [776]\n",
      " [777]\n",
      " [778]\n",
      " [779]\n",
      " [780]\n",
      " [781]\n",
      " [782]\n",
      " [783]\n",
      " [784]\n",
      " [785]\n",
      " [786]\n",
      " [787]\n",
      " [788]\n",
      " [789]\n",
      " [790]\n",
      " [791]\n",
      " [792]\n",
      " [793]\n",
      " [794]\n",
      " [795]\n",
      " [796]\n",
      " [797]\n",
      " [798]\n",
      " [799]\n",
      " [800]\n",
      " [801]\n",
      " [802]\n",
      " [803]\n",
      " [804]\n",
      " [805]\n",
      " [806]\n",
      " [807]\n",
      " [808]\n",
      " [809]\n",
      " [810]\n",
      " [811]\n",
      " [812]\n",
      " [813]\n",
      " [814]\n",
      " [815]\n",
      " [816]\n",
      " [817]\n",
      " [818]\n",
      " [819]\n",
      " [820]\n",
      " [821]\n",
      " [822]\n",
      " [823]\n",
      " [824]\n",
      " [825]\n",
      " [826]\n",
      " [827]\n",
      " [828]\n",
      " [829]\n",
      " [830]\n",
      " [831]\n",
      " [832]\n",
      " [833]\n",
      " [834]\n",
      " [835]\n",
      " [836]\n",
      " [837]\n",
      " [838]\n",
      " [839]\n",
      " [840]\n",
      " [841]\n",
      " [842]\n",
      " [843]\n",
      " [844]\n",
      " [845]\n",
      " [846]\n",
      " [847]\n",
      " [848]\n",
      " [849]\n",
      " [850]\n",
      " [851]\n",
      " [852]\n",
      " [853]\n",
      " [854]\n",
      " [855]\n",
      " [856]\n",
      " [857]\n",
      " [858]\n",
      " [859]\n",
      " [860]\n",
      " [861]\n",
      " [862]\n",
      " [863]\n",
      " [864]\n",
      " [865]\n",
      " [866]\n",
      " [867]\n",
      " [868]\n",
      " [869]\n",
      " [870]\n",
      " [871]\n",
      " [872]\n",
      " [873]\n",
      " [874]\n",
      " [875]\n",
      " [876]\n",
      " [877]\n",
      " [878]\n",
      " [879]\n",
      " [880]\n",
      " [881]\n",
      " [882]\n",
      " [883]\n",
      " [884]\n",
      " [885]\n",
      " [886]\n",
      " [887]\n",
      " [888]\n",
      " [889]\n",
      " [890]\n",
      " [891]\n",
      " [892]\n",
      " [893]\n",
      " [894]\n",
      " [895]\n",
      " [896]\n",
      " [897]\n",
      " [898]\n",
      " [899]\n",
      " [900]\n",
      " [901]\n",
      " [902]\n",
      " [903]\n",
      " [904]\n",
      " [905]\n",
      " [906]\n",
      " [907]\n",
      " [908]\n",
      " [909]\n",
      " [910]\n",
      " [911]\n",
      " [912]\n",
      " [913]\n",
      " [914]\n",
      " [915]\n",
      " [916]\n",
      " [917]\n",
      " [918]\n",
      " [919]\n",
      " [920]\n",
      " [921]\n",
      " [922]\n",
      " [923]\n",
      " [924]\n",
      " [925]\n",
      " [926]\n",
      " [927]\n",
      " [928]\n",
      " [929]\n",
      " [930]\n",
      " [931]\n",
      " [932]\n",
      " [933]\n",
      " [934]\n",
      " [935]\n",
      " [936]\n",
      " [937]\n",
      " [938]\n",
      " [939]\n",
      " [940]\n",
      " [941]\n",
      " [942]\n",
      " [943]\n",
      " [944]\n",
      " [945]\n",
      " [946]\n",
      " [947]\n",
      " [948]\n",
      " [949]\n",
      " [950]\n",
      " [951]\n",
      " [952]\n",
      " [953]\n",
      " [954]\n",
      " [955]\n",
      " [956]\n",
      " [957]\n",
      " [958]\n",
      " [959]\n",
      " [960]\n",
      " [961]\n",
      " [962]\n",
      " [963]\n",
      " [964]\n",
      " [965]\n",
      " [966]\n",
      " [967]\n",
      " [968]\n",
      " [969]\n",
      " [970]\n",
      " [971]\n",
      " [972]\n",
      " [973]\n",
      " [974]\n",
      " [975]\n",
      " [976]\n",
      " [977]\n",
      " [978]\n",
      " [979]\n",
      " [980]\n",
      " [981]\n",
      " [982]\n",
      " [983]\n",
      " [984]\n",
      " [985]\n",
      " [986]\n",
      " [987]\n",
      " [988]\n",
      " [989]\n",
      " [990]\n",
      " [991]\n",
      " [992]\n",
      " [993]\n",
      " [994]\n",
      " [995]\n",
      " [996]\n",
      " [997]\n",
      " [998]\n",
      " [999]]\n",
      "Code ran in 4.9917 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\envs\\tlshCluster\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:250: ConvergenceWarning: Affinity propagation did not converge, this model will not have any cluster centers.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "start = time.perf_counter()\n",
    "\n",
    "res = runAP(tlist,5)\n",
    "\n",
    "end = round(time.perf_counter() - start,4)\n",
    "print(\"Code ran in \" + str(end) + \" seconds\")\n",
    "\n",
    "#outfile = path + \"/output/\" + filename + \"_kmean_out.txt\"\n",
    "#outputClusters(outfile, tlist, res.labels_, labelList)\n",
    "\n",
    "#dict = getResult(\"tlsh\",\"ap\",labelList,res.labels_)\n",
    "#df = df.append(dict, ignore_index = True)\n",
    "#df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a2edd772",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AffinityPropagation(random_state=5)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5304871f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.labels_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1052437b",
   "metadata": {},
   "source": [
    "# Mean Shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ad493498",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Code ran in 0.535 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MeanShift(bandwidth=2)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cluster import MeanShift\n",
    "\n",
    "start = time.perf_counter()\n",
    "\n",
    "tdata = tlist2cdata(tlist)\n",
    "\n",
    "res = MeanShift(bandwidth=2).fit(tdata)\n",
    "\n",
    "end = round(time.perf_counter() - start,4)\n",
    "print(\"Code ran in \" + str(end) + \" seconds\")\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e4922895",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([332, 332, 332, 331, 331, 331, 330, 330, 330, 329, 329, 329, 328,\n",
       "       328, 328, 327, 327, 327, 326, 326, 326, 325, 325, 325, 324, 324,\n",
       "       324, 323, 323, 323, 322, 322, 322, 321, 321, 321, 320, 320, 320,\n",
       "       319, 319, 319, 318, 318, 318, 317, 317, 317, 316, 316, 316, 315,\n",
       "       315, 315, 314, 314, 314, 313, 313, 313, 312, 312, 312, 311, 311,\n",
       "       311, 310, 310, 310, 309, 309, 309, 308, 308, 308, 307, 307, 307,\n",
       "       306, 306, 306, 305, 305, 305, 304, 304, 304, 303, 303, 303, 302,\n",
       "       302, 302, 301, 301, 301, 300, 300, 300, 299, 299, 299, 298, 298,\n",
       "       298, 297, 297, 297, 296, 296, 296, 295, 295, 295, 294, 294, 294,\n",
       "       293, 293, 293, 292, 292, 292, 291, 291, 291, 290, 290, 290, 289,\n",
       "       289, 289, 288, 288, 288, 287, 287, 287, 286, 286, 286, 285, 285,\n",
       "       285, 284, 284, 284, 283, 283, 283, 282, 282, 282, 281, 281, 281,\n",
       "       280, 280, 280, 279, 279, 279, 278, 278, 278, 277, 277, 277, 276,\n",
       "       276, 276, 275, 275, 275, 274, 274, 274, 273, 273, 273, 272, 272,\n",
       "       272, 271, 271, 271, 270, 270, 270, 269, 269, 269, 268, 268, 268,\n",
       "       267, 267, 267, 266, 266, 266, 265, 265, 265, 264, 264, 264, 263,\n",
       "       263, 263, 262, 262, 262, 261, 261, 261, 260, 260, 260, 259, 259,\n",
       "       259, 258, 258, 258, 257, 257, 257, 256, 256, 256, 255, 255, 255,\n",
       "       254, 254, 254, 253, 253, 253, 252, 252, 252, 251, 251, 251, 250,\n",
       "       250, 250, 249, 249, 249, 248, 248, 248, 247, 247, 247, 246, 246,\n",
       "       246, 245, 245, 245, 244, 244, 244, 243, 243, 243, 242, 242, 242,\n",
       "       241, 241, 241, 240, 240, 240, 239, 239, 239, 238, 238, 238, 237,\n",
       "       237, 237, 236, 236, 236, 235, 235, 235, 234, 234, 234, 233, 233,\n",
       "       233, 232, 232, 232, 231, 231, 231, 230, 230, 230, 229, 229, 229,\n",
       "       228, 228, 228, 227, 227, 227, 226, 226, 226, 225, 225, 225, 224,\n",
       "       224, 224, 223, 223, 223, 222, 222, 222, 221, 221, 221, 220, 220,\n",
       "       220, 219, 219, 219, 218, 218, 218, 217, 217, 217, 216, 216, 216,\n",
       "       215, 215, 215, 214, 214, 214, 213, 213, 213, 212, 212, 212, 211,\n",
       "       211, 211, 210, 210, 210, 209, 209, 209, 208, 208, 208, 207, 207,\n",
       "       207, 206, 206, 206, 205, 205, 205, 204, 204, 204, 203, 203, 203,\n",
       "       202, 202, 202, 201, 201, 201, 200, 200, 200, 199, 199, 199, 198,\n",
       "       198, 198, 197, 197, 197, 196, 196, 196, 195, 195, 195, 194, 194,\n",
       "       194, 193, 193, 193, 192, 192, 192, 191, 191, 191, 190, 190, 190,\n",
       "       189, 189, 189, 188, 188, 188, 187, 187, 187, 186, 186, 186, 185,\n",
       "       185, 185, 184, 184, 184, 183, 183, 183, 182, 182, 182, 181, 181,\n",
       "       181, 180, 180, 180, 179, 179, 179, 178, 178, 178, 177, 177, 177,\n",
       "       176, 176, 176, 175, 175, 175, 174, 174, 174, 173, 173, 173, 172,\n",
       "       172, 172, 171, 171, 171, 170, 170, 170, 169, 169, 169, 168, 168,\n",
       "       168, 167, 167, 167, 166, 166, 166, 165, 165, 165, 164, 164, 164,\n",
       "       163, 163, 163, 162, 162, 162, 161, 161, 161, 160, 160, 160, 159,\n",
       "       159, 159, 158, 158, 158, 157, 157, 157, 156, 156, 156, 155, 155,\n",
       "       155, 154, 154, 154, 153, 153, 153, 152, 152, 152, 151, 151, 151,\n",
       "       150, 150, 150, 149, 149, 149, 148, 148, 148, 147, 147, 147, 146,\n",
       "       146, 146, 145, 145, 145, 144, 144, 144, 143, 143, 143, 142, 142,\n",
       "       142, 141, 141, 141, 140, 140, 140, 139, 139, 139, 138, 138, 138,\n",
       "       137, 137, 137, 136, 136, 136, 135, 135, 135, 134, 134, 134, 133,\n",
       "       133, 133, 132, 132, 132, 131, 131, 131, 130, 130, 130, 129, 129,\n",
       "       129, 128, 128, 128, 127, 127, 127, 126, 126, 126, 125, 125, 125,\n",
       "       124, 124, 124, 123, 123, 123, 122, 122, 122, 121, 121, 121, 120,\n",
       "       120, 120, 119, 119, 119, 118, 118, 118, 117, 117, 117, 116, 116,\n",
       "       116, 115, 115, 115, 114, 114, 114, 113, 113, 113, 112, 112, 112,\n",
       "       111, 111, 111, 110, 110, 110, 109, 109, 109, 108, 108, 108, 107,\n",
       "       107, 107, 106, 106, 106, 105, 105, 105, 104, 104, 104, 103, 103,\n",
       "       103, 102, 102, 102, 101, 101, 101, 100, 100, 100,  99,  99,  99,\n",
       "        98,  98,  98,  97,  97,  97,  96,  96,  96,  95,  95,  95,  94,\n",
       "        94,  94,  93,  93,  93,  92,  92,  92,  91,  91,  91,  90,  90,\n",
       "        90,  89,  89,  89,  88,  88,  88,  87,  87,  87,  86,  86,  86,\n",
       "        85,  85,  85,  84,  84,  84,  83,  83,  83,  82,  82,  82,  81,\n",
       "        81,  81,  80,  80,  80,  79,  79,  79,  78,  78,  78,  77,  77,\n",
       "        77,  76,  76,  76,  75,  75,  75,  74,  74,  74,  73,  73,  73,\n",
       "        72,  72,  72,  71,  71,  71,  70,  70,  70,  69,  69,  69,  68,\n",
       "        68,  68,  67,  67,  67,  66,  66,  66,  65,  65,  65,  64,  64,\n",
       "        64,  63,  63,  63,  62,  62,  62,  61,  61,  61,  60,  60,  60,\n",
       "        59,  59,  59,  58,  58,  58,  57,  57,  57,  56,  56,  56,  55,\n",
       "        55,  55,  54,  54,  54,  53,  53,  53,  52,  52,  52,  51,  51,\n",
       "        51,  50,  50,  50,  49,  49,  49,  48,  48,  48,  47,  47,  47,\n",
       "        46,  46,  46,  45,  45,  45,  44,  44,  44,  43,  43,  43,  42,\n",
       "        42,  42,  41,  41,  41,  40,  40,  40,  39,  39,  39,  38,  38,\n",
       "        38,  37,  37,  37,  36,  36,  36,  35,  35,  35,  34,  34,  34,\n",
       "        33,  33,  33,  32,  32,  32,  31,  31,  31,  30,  30,  30,  29,\n",
       "        29,  29,  28,  28,  28,  27,  27,  27,  26,  26,  26,  25,  25,\n",
       "        25,  24,  24,  24,  23,  23,  23,  22,  22,  22,  21,  21,  21,\n",
       "        20,  20,  20,  19,  19,  19,  18,  18,  18,  17,  17,  17,  16,\n",
       "        16,  16,  15,  15,  15,  14,  14,  14,  13,  13,  13,  12,  12,\n",
       "        12,  11,  11,  11,  10,  10,  10,   9,   9,   9,   8,   8,   8,\n",
       "         7,   7,   7,   6,   6,   6,   5,   5,   5,   4,   4,   4,   3,\n",
       "         3,   3,   2,   2,   2,   1,   1,   1,   0,   0,   0,   0],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.labels_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8a69ed7",
   "metadata": {},
   "source": [
    "# Spectral Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "747d1566",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Code ran in 0.5849 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SpectralClustering(assign_labels='discretize', n_clusters=56, random_state=0)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cluster import SpectralClustering\n",
    "\n",
    "start = time.perf_counter()\n",
    "\n",
    "tdata = tlist2cdata(tlist)\n",
    "\n",
    "res = SpectralClustering(n_clusters=nlable, assign_labels='discretize', \n",
    "                         random_state=0).fit(tdata)\n",
    "\n",
    "end = round(time.perf_counter() - start,4)\n",
    "print(\"Code ran in \" + str(end) + \" seconds\")\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ac2a936f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 38, 38,\n",
       "       38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 34,\n",
       "       34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34,\n",
       "       34, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31,\n",
       "       31, 31,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,\n",
       "        3,  3,  3,  3,  3,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,\n",
       "        4,  4,  4,  4,  4,  4,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,\n",
       "        5,  5,  5,  5,  5,  5,  5,  5, 21, 21, 21, 21, 21, 21, 21, 21, 21,\n",
       "       21, 21, 21, 21, 21, 21, 21, 21, 21,  6,  6,  6,  6,  6,  6,  6,  6,\n",
       "        6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  7,  7,  7,  7,  7,  7,  7,\n",
       "        7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  8,  8,  8,  8,  8,  8,\n",
       "        8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  9,  9,  9,  9,  9,\n",
       "        9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9, 10, 10, 10, 10,\n",
       "       10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 11, 11, 11,\n",
       "       11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 12, 12,\n",
       "       12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13,\n",
       "       13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13,\n",
       "       14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14,\n",
       "       14, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15,\n",
       "       15, 15, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "       16, 16, 16, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17,\n",
       "       17, 17, 17, 17, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18,\n",
       "       18, 18, 18, 18, 18, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19,\n",
       "       19, 19, 19, 19, 19, 19, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
       "       20, 20, 20, 20, 20, 20, 20, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22,\n",
       "       22, 22, 22, 22, 22, 22, 22, 22, 23, 23, 23, 23, 23, 23, 23, 23, 23,\n",
       "       23, 23, 23, 23, 23, 23, 23, 23, 23, 24, 24, 24, 24, 24, 24, 24, 24,\n",
       "       24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 25, 25, 25, 25, 25, 25, 25,\n",
       "       25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 26, 26, 26, 26, 26, 26,\n",
       "       26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 27, 27, 27, 27, 27,\n",
       "       27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 28, 28, 28, 28,\n",
       "       28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 29, 29, 29,\n",
       "       29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 30, 30,\n",
       "       30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 32,\n",
       "       32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32,\n",
       "       33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33,\n",
       "       33, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35,\n",
       "       35, 35, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36,\n",
       "       36, 36, 36, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,\n",
       "       37, 37, 37, 37, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39,\n",
       "       39, 39, 39, 39, 39, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40,\n",
       "       40, 40, 40, 40, 40, 40, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42,\n",
       "       42, 42, 42, 42, 42, 42, 42, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43,\n",
       "       43, 43, 43, 43, 43, 43, 43, 43, 44, 44, 44, 44, 44, 44, 44, 44, 44,\n",
       "       44, 44, 44, 44, 44, 44, 44, 44, 44, 45, 45, 45, 45, 45, 45, 45, 45,\n",
       "       45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 46, 46, 46, 46, 46, 46, 46,\n",
       "       46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 48, 48, 48, 48, 48, 48,\n",
       "       48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 49, 49, 49, 49, 49,\n",
       "       49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 50, 50, 50, 50,\n",
       "       50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50,  1,  1,  1,  1,\n",
       "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1, 52, 52, 52,\n",
       "       52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 51, 51,\n",
       "       51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 53, 53,\n",
       "       53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 55,\n",
       "       55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55,  2,\n",
       "        2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,\n",
       "       54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54,\n",
       "       47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.labels_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1342772",
   "metadata": {},
   "source": [
    "# OPTICS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3f4c2e6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Code ran in 0.4937 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "OPTICS(min_samples=2)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cluster import OPTICS\n",
    "\n",
    "start = time.perf_counter()\n",
    "\n",
    "tdata = tlist2cdata(tlist)\n",
    "\n",
    "res = OPTICS(min_samples=2).fit(tdata)\n",
    "\n",
    "end = round(time.perf_counter() - start,4)\n",
    "print(\"Code ran in \" + str(end) + \" seconds\")\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f44c7acf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.labels_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5621ba8b",
   "metadata": {},
   "source": [
    "# Birch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "02986f3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Code ran in 0.0551 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Birch(n_clusters=56)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cluster import Birch\n",
    "\n",
    "start = time.perf_counter()\n",
    "\n",
    "tdata = tlist2cdata(tlist)\n",
    "\n",
    "res = Birch(n_clusters=nlable).fit(tdata)\n",
    "\n",
    "end = round(time.perf_counter() - start,4)\n",
    "print(\"Code ran in \" + str(end) + \" seconds\")\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b62232f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 49,\n",
       "       49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 38, 38,\n",
       "       38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 40, 40, 40,\n",
       "       40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 37, 37, 37, 37,\n",
       "       37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 51, 51, 51, 51, 51,\n",
       "       51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 32, 32, 32, 32, 32, 32,\n",
       "       32, 32, 32, 32, 32, 32, 32, 32, 32, 32,  3,  3,  3,  3,  3,  3,  3,\n",
       "        3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,\n",
       "        3,  3,  3,  3,  3,  3,  3,  3, 36, 36, 36, 36, 36, 36, 36, 36, 36,\n",
       "       36, 36, 36, 36, 36, 36, 36, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31,\n",
       "       31, 31, 31, 31, 31, 31, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35,\n",
       "       35, 35, 35, 35, 35, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18,\n",
       "       18, 18, 18, 18, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15,\n",
       "       15, 15, 15,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "        1, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30,\n",
       "        6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,\n",
       "        6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  5,  5,\n",
       "        5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,\n",
       "        5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5, 34, 34, 34, 34,\n",
       "       34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 29, 29, 29, 29, 29,\n",
       "       29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 14, 14, 14, 14, 14, 14,\n",
       "       14, 14, 14, 14, 14, 14, 14, 14, 14, 14,  2,  2,  2,  2,  2,  2,  2,\n",
       "        2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,\n",
       "        2,  2,  2,  2,  2,  2,  2,  2,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55,\n",
       "       55, 55, 55, 55, 55, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17,\n",
       "       17, 17, 17, 17, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54,\n",
       "       54, 54, 54, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27,\n",
       "       27, 27, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53,\n",
       "       53,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,\n",
       "       52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 47,\n",
       "       47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 25, 25,\n",
       "       25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 26, 26, 26,\n",
       "       26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 50, 50, 50, 50,\n",
       "       50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 28, 28, 28, 28, 28,\n",
       "       28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 24, 24, 24, 24, 24, 24,\n",
       "       24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 45, 45, 45, 45, 45, 45, 45,\n",
       "       45, 45, 45, 45, 45, 45, 45, 45, 45, 48, 48, 48, 48, 48, 48, 48, 48,\n",
       "       48, 48, 48, 48, 48, 48, 48, 48, 12, 12, 12, 12, 12, 12, 12, 12, 12,\n",
       "       12, 12, 12, 12, 12, 12, 12, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23,\n",
       "       23, 23, 23, 23, 23, 23, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33,\n",
       "       33, 33, 33, 33, 33, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46,\n",
       "       46, 46, 46, 46, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "       16, 16, 16, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22,\n",
       "       22, 22, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19,\n",
       "       19, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44,\n",
       "       43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 21,\n",
       "       21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 41, 41,\n",
       "       41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 42, 42, 42,\n",
       "       42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 10, 10, 10, 10,\n",
       "       10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 20, 20, 20, 20, 20,\n",
       "       20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 11, 11, 11, 11, 11, 11,\n",
       "       11, 11, 11, 11, 11, 11, 11, 11, 11, 11,  9,  9,  9,  9,  9,  9,  9,\n",
       "        9,  9,  9,  9,  9,  9,  9,  9,  9,  4,  4,  4,  4,  4,  4,  4,  4,\n",
       "        4,  4,  4,  4,  4,  4,  4,  4,  7,  7,  7,  7,  7,  7,  7,  7,  7,\n",
       "        7,  7,  7,  7,  7,  7,  7, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13,\n",
       "       13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1423344f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
